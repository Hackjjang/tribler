from types import SimpleNamespace
from unittest.mock import Mock, patch

import pytest

from tribler_core.components.metadata_store.db.orm_bindings.torrent_metadata import NEW_TORRENT_METADATA_CREATED
from tribler_core.components.tag.community.tag_payload import TagOperation, TagOperationEnum
from tribler_core.components.tag.db.tag_db import CLOCK_FOR_AUTOGENERATED_TAGS, PUBLIC_KEY_FOR_AUTO_GENERATED_TAGS
from tribler_core.components.tag.rules.tag_rules_processor import LAST_PROCESSED_TORRENT_ID, TagRulesProcessor

TEST_BATCH_SIZE = 100
TEST_INTERVAL = 0.1

# pylint: disable=redefined-outer-name, protected-access
@pytest.fixture
def tag_rules_processor():
    return TagRulesProcessor(notifier=Mock(), db=Mock(), mds=Mock(), batch_size=TEST_BATCH_SIZE, interval=TEST_INTERVAL)


def test_constructor(tag_rules_processor: TagRulesProcessor):
    # test that constructor of TagRulesProcessor works as expected
    assert tag_rules_processor.batch_size == TEST_BATCH_SIZE
    assert tag_rules_processor.interval == TEST_INTERVAL

    m: Mock = tag_rules_processor.notifier.add_observer
    m.assert_called_with(NEW_TORRENT_METADATA_CREATED, callback=tag_rules_processor.process_torrent_title)


@patch.object(TagRulesProcessor, 'save_tags')
def test_process_torrent_file(mocked_save_tags: Mock, tag_rules_processor: TagRulesProcessor):
    # test on None
    assert not tag_rules_processor.process_torrent_title(infohash=None, title='title')
    assert not tag_rules_processor.process_torrent_title(infohash=b'infohash', title=None)

    # test that process_torrent_title doesn't find any tags in the title
    assert not tag_rules_processor.process_torrent_title(infohash=b'infohash', title='title')
    mocked_save_tags.assert_not_called()

    # test that process_torrent_title does find tags in the title
    assert tag_rules_processor.process_torrent_title(infohash=b'infohash', title='title [tag]') == 1
    mocked_save_tags.assert_called_with(b'infohash', {'tag'})


def test_save_tags(tag_rules_processor: TagRulesProcessor):
    # test that tag_rules_processor calls TagDatabase with correct args
    expected_calls = [{'operation': TagOperation(infohash=b'infohash', operation=TagOperationEnum.ADD,
                                                 clock=CLOCK_FOR_AUTOGENERATED_TAGS,
                                                 creator_public_key=PUBLIC_KEY_FOR_AUTO_GENERATED_TAGS,
                                                 tag='tag1')},
                      {'operation': TagOperation(infohash=b'infohash', operation=TagOperationEnum.ADD,
                                                 clock=CLOCK_FOR_AUTOGENERATED_TAGS,
                                                 creator_public_key=PUBLIC_KEY_FOR_AUTO_GENERATED_TAGS,
                                                 tag='tag2')}]

    tag_rules_processor.save_tags(infohash=b'infohash', tags={'tag1', 'tag2'})
    actual_calls = [c.kwargs for c in tag_rules_processor.db.add_auto_generated_tag_operation.mock_calls]

    # compare two lists of dict
    assert [c for c in actual_calls if c not in expected_calls] == []


@patch.object(TagRulesProcessor, 'replace_task')
def test_schedule_new_process_batch_round(mocked_replace_task: Mock, tag_rules_processor: TagRulesProcessor):
    tag_rules_processor._schedule_new_process_batch_round()
    assert tag_rules_processor.interval == TEST_INTERVAL * 2
    assert tag_rules_processor.batch_size == TEST_BATCH_SIZE * 2
    tag_rules_processor.mds.set_value.assert_called_with(LAST_PROCESSED_TORRENT_ID, '0')
    mocked_replace_task.assert_called_once()


@patch.object(TagRulesProcessor, 'process_torrent_title', new=Mock(return_value=1))
def test_process_batch_within_the_boundary(tag_rules_processor: TagRulesProcessor):
    # test inner logic of `process_batch` in case this batch located within the boundary
    returned_batch_size = TEST_BATCH_SIZE // 2  # let's return a half of requested items

    def select(_):
        return [SimpleNamespace(infohash=i, title=i) for i in range(returned_batch_size)]

    tag_rules_processor.mds.TorrentMetadata.select = select
    tag_rules_processor.mds.get_value = lambda *_, **__: 0  # let's start from 0 for LAST_PROCESSED_TORRENT_ID

    # let's specify `max_rowid` in such a way that it is far more than end of the current batch
    tag_rules_processor.mds.get_max_rowid = lambda: TEST_BATCH_SIZE * 10

    # assert that actually returned count of processed items is equal to `returned_batch_size`
    assert tag_rules_processor.process_batch() == returned_batch_size

    # assert that actually stored last_processed_torrent_id is equal to `TEST_BATCH_SIZE`
    tag_rules_processor.mds.set_value.assert_called_with(LAST_PROCESSED_TORRENT_ID, str(TEST_BATCH_SIZE))


@patch.object(TagRulesProcessor, '_schedule_new_process_batch_round')
@patch.object(TagRulesProcessor, 'process_torrent_title', new=Mock(return_value=1))
def test_process_batch_beyond_the_boundary(mocked_schedule_new_process_batch_round: Mock,
                                           tag_rules_processor: TagRulesProcessor):
    # test inner logic of `process_batch` in case this batch located within the boundary
    returned_batch_size = TEST_BATCH_SIZE // 2  # let's return a half of requested items

    def select(_):
        return [SimpleNamespace(infohash=i, title=i) for i in range(returned_batch_size)]

    tag_rules_processor.mds.get_value = lambda *_, **__: 0  # let's start from 0 for LAST_PROCESSED_TORRENT_ID
    tag_rules_processor.mds.TorrentMetadata.select = select

    # let's specify `max_rowid` in such a way that it is less than end of the current batch
    tag_rules_processor.mds.get_max_rowid = lambda: returned_batch_size // 2

    # assert that actually returned count of processed items is equal to `returned_batch_size`
    assert tag_rules_processor.process_batch() == returned_batch_size
    mocked_schedule_new_process_batch_round.assert_called_once()
